# **脚本说明文档：爬取豆瓣电影Top250前125部电影信息**

## 1.项目目的

本脚本用于从豆瓣电影网站（https://movie.douban.com/top250）爬取Top250排名前125的电影信息，并将相关数据保存到Excel文件中。爬取的信息包括电影名称、评分、评价人数、概况、导演/演员等。





## 2.功能概述

### 2.1爬取电影数据：

​	通过访问豆瓣电影Top250的多个页面，爬取电影详情、图片链接、评分、评价人数、概况等信息。

### 2.2数据保存：

​	将爬取的电影数据存储到Excel文件中，方便用户查看与分析。





## 3.使用环境

### 必要的Python库

```python
from bs4 import BeautifulSoup
import re  
import urllib.request, urllib.error 
import openpyxl  
```

- `BeautifulSoup`：用于HTML解析。
- `re`：正则表达式模块，用于匹配HTML中的相关数据。
- `urllib`：用于发送网络请求并获取网页内容。
- `openpyxl`：用于操作Excel文件。

### 安装依赖

在使用脚本之前，请确保已安装必要的库。你可以通过以下命令安装这些库：

```bash
pip install beautifulsoup4 openpyxl
```

### Python版本

脚本适用于Python 3.x版本。





## 4. 使用方法

### 4.1 配置脚本

#### ①**获取电影数据的URL列表**

 在脚本中定义了5个自定义的豆瓣电影Top250页面链接（每页25部电影，共5页，总共125部电影）。这些链接是固定的，如果需要抓取更多的电影，可以自行修改`custom_urls`变量。

```python
custom_urls = [
    "https://movie.douban.com/top250?start=0",   # 第1页
    "https://movie.douban.com/top250?start=25",  # 第2页
    "https://movie.douban.com/top250?start=50",  # 第3页
    "https://movie.douban.com/top250?start=75",  # 第4页
    "https://movie.douban.com/top250?start=100"  # 第5页
]
```

#### ②**设置保存路径**

 在脚本中，抓取到的数据将被保存到指定的Excel文件路径。你可以修改`savepath`变量中的文件路径和文件名：

```python
savepath = ".\\豆瓣电影Top250前125的相关信息.xlsx"  # 保存为xlsx格式
```

### 4.2 运行脚本

直接运行脚本即可开始抓取数据。确保已安装所有依赖库，并且设置了正确的URL和保存路径。

```bash
bashpython douban_movie_scraper.py
```

运行成功后，脚本将输出：

```
爬取成功！！！
```

同时会在指定的路径生成一个名为`豆瓣电影Top250前125的相关信息.xlsx`的Excel文件，里面包含了抓取的电影信息。

### 4.3 输出数据格式

生成的Excel文件包含以下列：

- **电影详情链接**：电影的详细页面URL。
- **图片链接**：电影的封面图片URL。
- **影片中文名**：电影的中文名称。
- **影片外国名**：电影的外国名称（如果有）。
- **评分**：该电影的豆瓣评分。
- **评价数**：该电影的评价人数。
- **概况**：电影的简短描述（如剧情简介等）。
- **相关信息**：包含导演、演员等其他信息（如电影类型、时长等）。





## 5. 代码详细说明

### 5.1 正则表达式匹配模式

该脚本通过正则表达式从HTML中提取每部电影的相关数据。以下是正则表达式的定义：

```python
findLink = re.compile(r'<a href="(.*?)">')  # 影片详情链接
findImgSrc = re.compile(r'<img.*src="(.*?)"', re.S)  # 图片链接
findTitle = re.compile(r'<span class="title">(.*)</span>')  # 影片名称
findRating = re.compile(r'<span class="rating_num" property="v:average">(.*)</span>')  # 评分
findJudge = re.compile(r'<span>(\d*)人评价</span>')  # 评价人数
findInq = re.compile(r'<span class="inq">(.*)</span>')  # 简短概况
findBd = re.compile(r'<p class="">(.*?)</p>', re.S)  # 相关信息（导演、演员等）
```

### 5.2 获取网页内容

通过`geturl()`函数，脚本发送HTTP请求并获取网页内容：

```python
	def geturl(url):
    head = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36"
    }
    req = urllib.request.Request(url, headers=head)
    try:
        response = urllib.request.urlopen(req)
        html = response.read().decode("utf-8")
    except urllib.error.URLError as e:
        if hasattr(e, "code"):
            print(e.code)
        if hasattr(e, "reason"):
            print(e.reason)
    return html
```

### 5.3 数据提取与处理

在`getdata()`函数中，脚本利用BeautifulSoup和正则表达式提取每一部电影的相关信息，存储到一个二维列表`datalist`中。

```python
    def getdata(url_list):
    datalist = []
    for url in url_list:  # 遍历自定义的网页链接
        html = geturl(url)  # 获取页面HTML内容
        soup = BeautifulSoup(html, "html.parser")  # 解析HTML
        for item in soup.find_all("div", class_='item'):  # 找到每部电影的item
            data = []  # 保存单部电影的所有信息
            item = str(item)  # 转换为字符串便于正则匹配

            # 提取数据
            link = re.findall(findLink, item)[0]
            data.append(link)

            imgSrc = re.findall(findImgSrc, item)[0]
            data.append(imgSrc)

            titles = re.findall(findTitle, item)
            if len(titles) == 2:
                onetitle = titles[0]
                data.append(onetitle)
                twotitle = titles[1].replace("/", "")  # 去掉斜杠
                data.append(twotitle)
            else:
                data.append(titles[0])
                data.append(" ")

            rating = re.findall(findRating, item)[0]
            data.append(rating)

            judgeNum = re.findall(findJudge, item)[0]
            data.append(judgeNum)

            inq = re.findall(findInq, item)
            if len(inq) != 0:
                inq = inq[0].replace("。", "")
                data.append(inq)
            else:
                data.append(" ")

            bd = re.findall(findBd, item)[0]
            bd = re.sub('<br(\s+)?/>(\s+)?', " ", bd)
            bd = re.sub('/', " ", bd)
            data.append(bd.strip())

            datalist.append(data)
    return datalist
```

### 5.4 保存数据到Excel

通过`openpyxl`库，脚本将抓取到的数据保存到一个新的Excel文件中。在`savedata()`函数中，脚本创建并写入Excel表格：

```python
	def savedata(datalist, savepath):
    workbook = openpyxl.Workbook()  # 创建新的工作簿
    worksheet = workbook.active  # 获取当前活动工作表
    worksheet.title = "豆瓣电影Top250前125的相关信息"  # 设置工作表名称

    # 写入Excel标题行
    column = ("电影详情链接", "图片链接", "影片中文名", "影片外国名", "评分", "评价数", "概况", "相关信息")
    for i in range(8):
        worksheet.cell(row=1, column=i + 1, value=column[i])  # 设置表头

    # 写入电影数据
    for i in range(len(datalist)):
        data = datalist[i]
        for j in range(8):
            worksheet.cell(row=i + 2, column=j + 1, value=data[j])  # 设置每一行的数据

    workbook.save(savepath)  # 保存到指定路径
```





## 6.示例输出

当脚本成功运行时，Excel文件将包含如下表头：

| 电影详情链接                       | 图片链接                                                     | 影片中文名 | 影片外国名 | 评分 | 评价数 | 概况                       | 相关信息                         |
| ---------------------------------- | ------------------------------------------------------------ | ---------- | ---------- | ---- | ------ | -------------------------- | -------------------------------- |
| /subject/1292052/                  | https://img3.doubanio.com/view/photo/l/public/p1910907697.jpg | 肯德基     | KFC        | 8.7  | 13586  | 一部快餐主题的黑色幽默电影 | 导演: 张艺谋; 主演: 葛优, 李冰冰 |
| …                                  | …                                                            | …          | …          | …    | …      | …                          | …                                |
| 每一行数据表示一部电影的详细信息。 |                                                              |            |            |      |        |                            |                                  |






## 7.注意事项

### 7.1反爬机制：

豆瓣可能会对频繁访问的IP实施限制，建议控制访问频率，避免被封禁。

### 7.2代码修改：

若需要爬取其他页面或修改数据格式，可以根据实际需求调整custom_urls列表和正则表达式。